{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2025ddc2",
   "metadata": {},
   "source": [
    "# Hoja de trabajo 2\n",
    "\n",
    "Link del repositorio: https://github.com/faguilarleal/HDT2_deep  \n",
    "\n",
    "\n",
    "Integrantes:  \n",
    "- Franci Aguilar 22243\n",
    "- César López 22404\n",
    "\n",
    "\n",
    "## Ejercicio 1. Experimentación práctica\n",
    "#### Task 1 - Preparación del conjunto de datos\n",
    "Cargue el conjunto de datos de Iris utilizando bibliotecas como sklearn.datasets. Luego, divida el conjunto de datos en conjuntos de entrenamiento y validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee791006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d745e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "Tamaños de los conjuntos:\n",
      "Entrenamiento: (120, 4) (120,)\n",
      "Validación: (30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Convertir a DataFrame para verlo más ordenado\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nTamaños de los conjuntos:\")\n",
    "print(\"Entrenamiento:\", X_train.shape, y_train.shape)\n",
    "print(\"Validación:\", X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd4fff",
   "metadata": {},
   "source": [
    "#### Task 2 - Arquitectura modelo\n",
    "Cree una red neuronal feedforward simple utilizando nn.Module de PyTorch. Luego, defina capa de entrada, capas ocultas y capa de salida. Después, elija las funciones de activación y el número de neuronas por capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24de36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisNet(\n",
      "  (fc1): Linear(in_features=4, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc3): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class IrisNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNet, self).__init__()\n",
    "        # Capa de entrada -> 4 neuronas \n",
    "        # Primera capa oculta -> 16 neuronas\n",
    "        # Segunda capa oculta -> 8 neuronas\n",
    "        # Capa de salida -> 3 neuronas (porque iris tiene 3 clases)\n",
    "        self.fc1 = nn.Linear(4, 16)   # entrada -> capa oculta 1\n",
    "        self.fc2 = nn.Linear(16, 8)   # capa oculta 1 -> capa oculta 2\n",
    "        self.fc3 = nn.Linear(8, 3)    # capa oculta 2 -> salida\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Funciones de activación\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        x = F.relu(self.fc2(x))  \n",
    "        x = self.fc3(x)         \n",
    "        return x\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = IrisNet()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf12011",
   "metadata": {},
   "source": [
    "#### Task 3 - Funciones de Pérdida\n",
    "Utilice diferentes funciones de pérdida comunes como Cross-Entropy Loss y MSE para clasificación. Entrene el modelo con diferentes funciones de pérdida y registre las pérdidas de entrenamiento y test. Debe utilizar al menos 3 diferentes funciones. Es decir, procure que su código sea capaz de parametrizar el uso de diferentes funciones de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09cd6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francis\\AppData\\Local\\Temp\\ipykernel_13540\\3936418881.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\Francis\\AppData\\Local\\Temp\\ipykernel_13540\\3936418881.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.long)\n",
      "C:\\Users\\Francis\\AppData\\Local\\Temp\\ipykernel_13540\\3936418881.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val   = torch.tensor(X_val, dtype=torch.float32)\n",
      "C:\\Users\\Francis\\AppData\\Local\\Temp\\ipykernel_13540\\3936418881.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val   = torch.tensor(y_val, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CrossEntropy] Epoch 10/50 Train Loss: 0.9479 | Val Loss: 0.9315\n",
      "[CrossEntropy] Epoch 20/50 Train Loss: 0.6997 | Val Loss: 0.6743\n",
      "[CrossEntropy] Epoch 30/50 Train Loss: 0.5057 | Val Loss: 0.4973\n",
      "[CrossEntropy] Epoch 40/50 Train Loss: 0.4258 | Val Loss: 0.4271\n",
      "[CrossEntropy] Epoch 50/50 Train Loss: 0.3896 | Val Loss: 0.3947\n",
      "[MSE] Epoch 10/50 Train Loss: 0.2186 | Val Loss: 0.2074\n",
      "[MSE] Epoch 20/50 Train Loss: 0.1471 | Val Loss: 0.1383\n",
      "[MSE] Epoch 30/50 Train Loss: 0.1087 | Val Loss: 0.1099\n",
      "[MSE] Epoch 40/50 Train Loss: 0.1011 | Val Loss: 0.1030\n",
      "[MSE] Epoch 50/50 Train Loss: 0.0932 | Val Loss: 0.0945\n",
      "[NLLLoss] Epoch 10/50 Train Loss: 0.9667 | Val Loss: 0.9414\n",
      "[NLLLoss] Epoch 20/50 Train Loss: 0.6885 | Val Loss: 0.6628\n",
      "[NLLLoss] Epoch 30/50 Train Loss: 0.4754 | Val Loss: 0.4628\n",
      "[NLLLoss] Epoch 40/50 Train Loss: 0.3327 | Val Loss: 0.3283\n",
      "[NLLLoss] Epoch 50/50 Train Loss: 0.2159 | Val Loss: 0.2181\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val   = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val   = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "#  Funciones de pérdida disponibles\n",
    "loss_functions = {\n",
    "    \"CrossEntropy\": nn.CrossEntropyLoss(),\n",
    "    \"MSE\": nn.MSELoss(),  # MSE requiere one-hot en y\n",
    "    \"NLLLoss\": nn.NLLLoss()  # requiere log_softmax en salida\n",
    "}\n",
    "\n",
    "\n",
    "#  Entrenamiento parametrizable\n",
    "def train_model(loss_name, epochs=50, lr=0.01):\n",
    "    model = IrisNet()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    criterion = loss_functions[loss_name]\n",
    "\n",
    "    # Para NLL necesitamos modificar el forward (añadir log_softmax)\n",
    "    use_log_softmax = (loss_name == \"NLLLoss\")\n",
    "\n",
    "    # Para MSE necesitamos one-hot encoding de las etiquetas\n",
    "    if loss_name == \"MSE\":\n",
    "        y_train_oh = torch.nn.functional.one_hot(y_train, num_classes=3).float()\n",
    "        y_val_oh   = torch.nn.functional.one_hot(y_val, num_classes=3).float()\n",
    "    else:\n",
    "        y_train_oh, y_val_oh = y_train, y_val\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Forward ---\n",
    "        outputs = model(X_train)\n",
    "        if use_log_softmax:\n",
    "            outputs = torch.log_softmax(outputs, dim=1)\n",
    "\n",
    "        loss = criterion(outputs, y_train_oh)\n",
    "\n",
    "        # --- Backprop ---\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # --- Evaluación en validación ---\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            if use_log_softmax:\n",
    "                val_outputs = torch.log_softmax(val_outputs, dim=1)\n",
    "            val_loss = criterion(val_outputs, y_val_oh)\n",
    "\n",
    "        history[\"train_loss\"].append(loss.item())\n",
    "        history[\"val_loss\"].append(val_loss.item())\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"[{loss_name}] Epoch {epoch+1}/{epochs} \"\n",
    "                  f\"Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Entrenar con las tres funciones\n",
    "# -------------------------------\n",
    "hist_ce  = train_model(\"CrossEntropy\", epochs=50)\n",
    "hist_mse = train_model(\"MSE\", epochs=50)\n",
    "hist_nll = train_model(\"NLLLoss\", epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
